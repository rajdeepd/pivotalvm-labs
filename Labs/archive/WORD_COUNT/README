Introduction to Map/Reduce Lab: Word Count

This lab starts with the source code for the "word count" map/reduce example and
provides an Ant build.xml file to help make the edit/compile/run cycle simpler.

The source file, src/org/apache/hadoop/examples/WordCount.java, was taken from
the Hadoop source tree corresponding to the current release of Pivotal HD, the
"release-2.0.2-alpha" tag.  For your reference, this can be found here:

  http://svn.apache.org/repos/asf/hadoop/common/tags/release-2.0.2-alpha

The process of checking this out is to use a Subversion client (which you must
first install):

  svn co http://svn.apache.org/repos/asf/hadoop/common/tags/release-2.0.2-alpha

Apache Ant runs against the "build.xml" file within this directory.  To see a
complete list of "targets", run `ant -p'.  Note that the HDFS directory used in
this exercise is a relative path, without a leading '/', which means any file
created will be located within the "/users/gpadmin/" directory.  This exercise
creates a directory there called "word_count", places input into the "in" sub-
directory there, and output into the "out" directory.

[gpadmin@pivhdsne WORD_COUNT]$ ant -p
Buildfile: /home/gpadmin/Labs/WORD_COUNT/build.xml
Builds and runs the Hadoop WordCount example
Main targets:

Other targets:

 clean
 clean-hdfs
 compile
 init
 init-hdfs
 jar
 run-job
 Default target: jar

Suggestions for how to proceed:
  * Run `ant run-job' and observe the output
  * This is a very rudimentary word count program, so consider how to improve it
  * Keep versions of your changes
  * Improve/iterate
  * Change the input data set (this is the script to Hamlet)


